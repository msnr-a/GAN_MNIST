{"nbformat":4,"nbformat_minor":0,"metadata":{},"cells":[{"cell_type":"markdown","metadata":{},"source":["##GANLearner - 敵対的生成ネットワークを用いた深層学習や、画像生成機能を提供するクラス"]},{"cell_type":"code","metadata":{},"source":["import os\n","import re\n","import math\n","import datetime\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Sequential\n"," \n","class GANLearner:\n","    \"\"\"敵対的生成ネットワークを用いた深層学習や、画像生成機能を提供するクラス。\n"," \n","        Parameters\n","        ----------\n","        generator : tensorflow.keras.models.Sequential\\n\n","            生成器。識別器との結合は行われていない状態の生成器を指定する。\\n\n","        discriminator :  tensorflow.keras.models.Sequential\\n\n","            識別器のモデルを指定する。\\n\n","        batch_size : int\\n\n","            一度の学習で計算するデータ数を指定する。\\n\n","            default : 128\\n\n","            validation : >0\\n\n","        z_dim : int\\n\n","            生成画像の元となる特徴量を指定する。\n","            default : 100\\n\n","            validation : >0\\n\n","    \"\"\"\n"," \n","    # property\n","    __generator = None\n","    __discriminator = None\n","    __batch_size = 0\n","    __z_dim = 0\n","    __total_epochs = 0\n"," \n","    @property\n","    def generator(self):\n","        \"\"\"生成器を取得する。\"\"\"\n","        return self.__generator\n"," \n","    @property\n","    def discriminator(self):\n","        \"\"\"識別器を取得する。\"\"\"\n","        return self.__discriminator\n"," \n","    @property\n","    def batch_size(self):\n","        \"\"\"int : バッチサイズを取得、または設定する。\\n\n","            validation : >0\"\"\"\n","        return self.__batch_size\n"," \n","    @batch_size.setter\n","    def batch_size(self, value):\n","        \"\"\"int : バッチサイズを取得、または設定する。\\n\n","            validation : >0\"\"\"\n","        self.__batch_size = self.__validateNaturalNumber(value)\n"," \n","    @property\n","    def z_dim(self):\n","        \"\"\"int : 潜在変数の次元数を取得、または設定する。\\n\n","            validation : >0\"\"\"\n","        return self.__z_dim\n"," \n","    @z_dim.setter\n","    def z_dim(self, value):\n","        \"\"\"int : 潜在変数の次元数を取得、または設定する。\\n\n","            validation : >0\"\"\"\n","        self.__z_dim = self.__validateNaturalNumber(value)\n"," \n","    @property\n","    def total_epochs(self):\n","        \"\"\"int : インスタンスが生成されてから実行されたトレーニング数を取得する。\\n\"\"\"\n","        return self.__total_epochs\n"," \n","    # コンストラクタ\n","    def __init__(self, generator, discriminator, batch_size, z_dim):\n","        self.batch_size = batch_size\n","        self.z_dim = z_dim\n","        self.__discriminator = discriminator\n","        self.__generator = generator\n","    \n","    # 入力チェック（自然数）\n","    def __validateNaturalNumber(self, value):\n","        if not isinstance(value, int):\n","            raise TypeError(\"argument type must be int.\")\n","        elif value <= 0:\n","            raise ValueError(\"need more than 1 value.\")\n","        else:\n","            return value\n"," \n","    # 生成器と識別器の結合とコンパイルを行う。\n","    def __recompile(self, generator, discriminator):\n","        \n","        # コンパイル確認\n","        if not generator._is_compiled or not discriminator._is_compiled:\n","            raise RuntimeError(\"You must compile a model before training.\")\n"," \n","        # discriminatorがcompile済のため、trainableをfalseにしても、discriminatorは学習できる\n","        discriminator.trainable = False\n"," \n","        # 結合\n","        combined = Sequential([generator, discriminator])\n"," \n","        # 結合済のgeneratorをcompile\n","        if generator.compiled_metrics == None:\n","            combined.compile(\n","                loss=generator.loss,\n","                optimizer=generator.optimizer)\n","        else:\n","            combined.compile(\n","                loss=generator.loss,\n","                optimizer=generator.optimizer,\n","                metrics=generator.compiled_metrics._user_metrics)\n","        \n","        return combined\n"," \n","    def defit(self, x_train, epochs=1, *steps):\n","        \"\"\"生成器と識別器を用いた学習を、エポック数回だけ実行する。\n"," \n","            Parameters\n","            ----------\n","            x_train : numpy.ndarray\\n\n","                学習データ\\n\n","            epochs :  int\\n\n","                エポック数。学習を繰り返す回数を指定する。\\n\n","                default : 1\\n\n","                validation : >0\\n\n","            steps : *int\n","                未使用（デバッグ用）\n","        \"\"\"\n","        for i in self.__defit(self.__generator, self.__discriminator, x_train, self.__validateNaturalNumber(epochs), self.__batch_size, self.__z_dim):\n","            if i in steps:\n","                pass # 未使用（デバッグ用）\n"," \n","    # defit本体。epoch単位で結果をyieldする。\n","    def __defit(self, generator, discriminator, x_train, epochs, batch_size, z_dim):\n","        \n","        # GモデルとDモデルを結合しコンパイル\n","        combined = self.__recompile(generator, discriminator)\n"," \n","        # カウンタ\n","        cnt = 0\n","        y_batch = int(batch_size / 2)\n"," \n","        # 結果表示用テンプレート\n","        print_header = lambda : print(f\"{self.total_epochs} [\", end=\"\")\n","        print_footer = lambda : print(f\"] D_MODEL - loss:{d_loss_ave[0]:.4f}, acc:{d_loss_ave[1] * 100:.2f}  G_MODEL - loss:{np.average(g_loss):.4f}\")\n","        \n","        while cnt < epochs:\n"," \n","            # 進捗\n","            self.__total_epochs += 1\n","            print_header()\n","            \n","            # 損失関数\n","            d_loss = np.zeros((batch_size, 2))\n","            g_loss = np.zeros(batch_size)\n"," \n","            for i in range(batch_size):\n","                \n","                # Generatorから生成 (num=batch_size/2)\n","                noise = np.random.normal(0, 1, (y_batch, z_dim))\n","                fake_imgs = generator.predict(noise)\n","                \n","                # 教師データ取得 (num=batch_size/2)\n","                idx = np.random.randint(0, x_train.shape[0], y_batch)\n","                imgs = x_train[idx]\n"," \n","                # Discriminatorの学習 - 訓練データを\"1\"と認識するよう、欠損値関数を元に学習\n","                d_loss_real = discriminator.train_on_batch(imgs, np.ones((y_batch, 1)))\n"," \n","                # Discriminatorの学習 - 訓練データを\"0\"と認識するよう、欠損値関数を元に学習\n","                d_loss_fake = discriminator.train_on_batch(fake_imgs, np.zeros((y_batch, 1)))\n"," \n","                # Generatorの学習 - ランダムな画像データを生成\n","                noise = np.random.normal(0, 1, (batch_size, z_dim))\n"," \n","                # Generatorの学習 - 生成データをDモデルが\"1\"と認識するように、損失関数を元に学習\n","                g_loss[i] = combined.train_on_batch(noise, np.array([1] * batch_size))\n"," \n","                # Discriminatorの損失関数の平均\n","                d_loss[i] = np.add(d_loss_real, d_loss_fake) / 2\n"," \n","                # 進捗表示\n","                if i % int(batch_size / 25) == 0: print(\"=\", end=\"\")\n","            \n","            # 損失関数表示\n","            d_loss_ave = np.average(d_loss, axis=0)\n","            print_footer()\n","            \n","            # 戻り値\n","            yield cnt\n","            cnt += 1\n"," \n","    def generateImage(self, fileName=None, num=20):\n","        \"\"\"学習データを基に、生成器で画像を生成する。\n"," \n","            Parameters\n","            ----------\n","            fileName : string\\n\n","                保存する画像ファイルのフルパスを指定する。指定しない場合は保存しない。\\n\n","                default : None\\n\n","            num :  int\\n\n","                生成する画像の個数を指定する。\\n\n","                default : 20\\n\n","                validation : >0\\n\n","            returns\n","            -------\n","            fig : figManager.canvas.figure\\n\n","                生成した画像を返す。\n","        \"\"\"\n"," \n","        # plotのrow、col\n","        c = math.ceil(math.sqrt(self.__validateNaturalNumber(num)))\n","        r = math.ceil(num / c)\n"," \n","        # numpy.random.normal(平均, 標準偏差 (配列の個数, 次元数))\n","        noise = np.random.normal(0, 1, (num, self.__z_dim))\n"," \n","        # 画像生成\n","        gen_imgs = self.__generator.predict(noise)\n"," \n","        # 生成画像を0-1に再スケール\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n"," \n","        # plotの初期化\n","        plt.ioff()\n","        fig, axs = plt.subplots(r, c)\n"," \n","        # 画像表示用ラムダ式\n","        func = lambda ax, idx: [ax.axis(\"off\"), ax.imshow(gen_imgs[idx, :, :, 0], cmap=\"gray\")]\n"," \n","        # 画像表示\n","        if num == 1:\n","            func(axs, 0)\n","        elif num == 2:\n","            func(axs[0], 0)\n","            func(axs[1], 1)\n","        else:\n","            cnt = 0\n","            for i in range(r):\n","                for j in range(c):\n","                    if cnt < num: func(axs[i, j], cnt)\n","                    else: axs[i, j].axis(\"off\")\n","                    cnt += 1\n"," \n","        # 保存してclose\n","        if fileName != None: fig.savefig(fileName)\n","        return fig\n"," \n","    def saveWeights(self, path):\n","        \"\"\"学習データを保存する。\n"," \n","            Parameters\n","            ----------\n","            path : string\\n\n","                保存するファイルのパス、またはディレクトリを指定する。\\n\n","                ディレクトリを指定した場合、保存ファイル名は{yyyymmddhhmmss}_mnist_{total_epochs}.h5となる。\\n\n","            returns\n","            -------\n","            filepath : string\\n\n","                保存したファイルのパスを返す。\n","        \"\"\"\n"," \n","        # 保存ファイル名のテンプレ\n","        SAVE_FILE_NAME = lambda : os.path.join(path, f\"{dt}_mnist_{self.total_epochs}.h5\")\n"," \n","        # ディレクトリの場合はテンプレで保存\n","        if os.path.isdir(path):\n","            dt = datetime.datetime.today().strftime('%Y%m%d%H%M%S')\n","            filename = SAVE_FILE_NAME()\n","        else:\n","            filename = path\n","        \n","        # 再コンパイルして保存\n","        combined = self.__recompile(self.__generator, self.__discriminator)\n","        combined.save_weights(filename)\n"," \n","        # 保存したファイルパスを戻す\n","        return filename\n"," \n","    def loadWeights(self, path):\n","        \"\"\"学習データを読込む。\n"," \n","            Parameters\n","            ----------\n","            path : string\\n\n","                読込むファイルのパス、またはディレクトリを指定する。\\n\n","                ディレクトリを指定した場合、ファイル名が\\d{14}_mnist_\\d+\\.h5であるファイルの内、ソート後の順が最後尾のファイルを使用する。\\n\n","            returns\n","            -------\n","            filepath : string\\n\n","                保存したファイルのパスを返す。\n","            raises\n","            ------\n","            FileNotFoundError\n","                読込むファイルが存在しない場合発生する。\n","        \"\"\"\n"," \n","        # 読込みファイル名の正規表現\n","        LOAD_FILE_NAME = \"\\d{14}_mnist_(\\d+)\\.h5\"\n"," \n","        # ディレクトリの場合はLOAD_FILE_NAMEをソート後の最後尾\n","        if os.path.isdir(path):\n"," \n","            # ファイルのみ取得\n","            files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n","            if len(files) == 0:\n","                raise FileNotFoundError(f\"No such file or directory: '{path}/*'\")\n","            \n","            # 学習ファイルを検索\n","            files = [f for f in files if re.match(LOAD_FILE_NAME, f)]\n","            if len(files) == 0:\n","                raise FileNotFoundError(f\"No such file or directory: '{path}/*'\")\n","            \n","            # 最新のファイル（最後尾）を取得\n","            files = sorted(files)\n","            filename = os.path.join(path, files[-1])\n"," \n","            # epoch番号取得\n","            num = re.match(LOAD_FILE_NAME, files[-1])\n","            self.__total_epochs = int(num.group(1))\n","            \n","        else:\n","            filename = path\n"," \n","        # 再コンパイルして読込み\n","        combined = self.__recompile(self.__generator, self.__discriminator)\n","        combined.load_weights(filename)\n"," \n","        # 読込んだファイルパスを戻す\n","        return filename"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["##models - generator, discriminatorを定義する"]},{"cell_type":"code","metadata":{},"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Activation\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","\n","def GAN_MODEL_1(noise_shape, img_shape):\n","\n","    # Gモデル\n","    generator = Sequential()\n","    generator.add(Dense(256, activation=\"relu\", input_shape=noise_shape))   # 入力層\n","    generator.add(Dense(512, activation=\"relu\"))                            # 中間層\n","    generator.add(Dense(1024, activation=\"relu\"))                           # 中間層\n","    generator.add(Dense(np.prod(img_shape), activation=\"tanh\"))             # 中間層\n","    generator.add(Reshape(img_shape))                                       # 出力層\n","    generator.summary()\n","\n","    # Dモデル\n","    discriminator = Sequential()\n","    discriminator.add(Flatten(input_shape=img_shape))\n","    discriminator.add(Dense(512, activation=\"relu\"))    # 入力層\n","    discriminator.add(Dense(256, activation=\"relu\"))    # 中間層\n","    discriminator.add(Dense(1, activation=\"sigmoid\"))   # 出力層\n","    discriminator.summary()\n","\n","    # 最適化手法\n","    optimizer = Adam(0.0002, 0.5)\n","\n","    # モデル構築\n","    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","    generator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n","\n","    return generator, discriminator\n","\n","\n","def DCGAN_MODEL_1(noise_shape, img_shape):\n","    \n","    generator = Sequential()\n","    generator.add(Dense(1024, activation=\"relu\", input_shape=noise_shape))\n","    generator.add(BatchNormalization()) #平均を0、分散が1に\n","    generator.add(Dense(7 * 7 * 128, activation=\"relu\"))\n","    generator.add(BatchNormalization())\n","    generator.add(Reshape((7, 7, 128), input_shape=(7 * 7 * 128, ))) # 畳み込み層に7*7の画像を与える\n","    generator.add(UpSampling2D((2, 2))) # UpSamplingをし、画像を14*14にする 間の要素は0で埋める\n","    generator.add(Conv2D(64, kernel_size=(5, 5), padding=\"same\", activation=\"relu\"))\n","    generator.add(UpSampling2D((2, 2))) # UpSamplingをし、画像を28*28にする\n","    generator.add(Conv2D(1, kernel_size=(5, 5), padding=\"same\", activation=\"tanh\")) # tanh:双曲線正接関数 (0,0基点の点対称S字型曲線で-1.0～1.0の値をとる)\n","    generator.summary()\n","\n","    leakyReLU = LeakyReLU(alpha=0.2)\n","    discriminator = Sequential()\n","    discriminator.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding=\"same\", activation=leakyReLU, input_shape=(img_shape))) # 畳み込む（ゼロパディングをし5*5のフィルタを2マスごとに動かす）\n","    discriminator.add(Conv2D(128, kernel_size=(5, 5), strides=(2, 2), activation=leakyReLU)) # 畳み込み2回目\n","    discriminator.add(Flatten()) # 入力の平坦化\n","    discriminator.add(Dense(256, activation=leakyReLU))\n","    discriminator.add(Dropout(0.5))\n","    discriminator.add(Dense(1, activation=\"sigmoid\"))\n","    discriminator.summary()\n","\n","    # 最適化関数\n","    optimizer = Adam(lr=0.0001, beta_1=0.5)\n","\n","    # モデル構築\n","    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","    generator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n","\n","    return generator, discriminator\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["##学習準備"]},{"cell_type":"code","metadata":{},"source":["import numpy as np\n","from tensorflow.keras.datasets import mnist\n","\n","#入力画像\n","IMG_ROWS  = 28 \n","IMG_COLS  = 28\n","IMG_CHNL  = 1\n","IMG_SHAPE = (IMG_ROWS, IMG_COLS, IMG_CHNL)\n","\n","# 潜在変数の次元数\n","Z_DIM = 100\n","\n","# バッチサイズ\n","BAT_SIZE = 128\n","\n","# テストデータ (mnist)\n","(x_train, _), (_, _) = mnist.load_data()\n","x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n","x_train = np.expand_dims(x_train, axis=3)\n","\n","# Gモデル、 Dモデル\n","generator, discriminator = DCGAN_MODEL_1((Z_DIM,), IMG_SHAPE)\n","\n","# 学習用モジュール\n","gan = GANLearner(\n","    generator=generator,\n","    discriminator=discriminator,\n","    batch_size=BAT_SIZE,\n","    z_dim=Z_DIM\n",")\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 1024)              103424    \n","                                                                 \n"," batch_normalization (BatchN  (None, 1024)             4096      \n"," ormalization)                                                   \n","                                                                 \n"," dense_1 (Dense)             (None, 6272)              6428800   \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 6272)             25088     \n"," hNormalization)                                                 \n","                                                                 \n"," reshape (Reshape)           (None, 7, 7, 128)         0         \n","                                                                 \n"," up_sampling2d (UpSampling2D  (None, 14, 14, 128)      0         \n"," )                                                               \n","                                                                 \n"," conv2d (Conv2D)             (None, 14, 14, 64)        204864    \n","                                                                 \n"," up_sampling2d_1 (UpSampling  (None, 28, 28, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 28, 28, 1)         1601      \n","                                                                 \n","=================================================================\n","Total params: 6,767,873\n","Trainable params: 6,753,281\n","Non-trainable params: 14,592\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 14, 14, 64)        1664      \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 5, 5, 128)         204928    \n","                                                                 \n"," flatten (Flatten)           (None, 3200)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 256)               819456    \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 1,026,305\n","Trainable params: 1,026,305\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"markdown","metadata":{},"source":["##トレーニング実行 & 画像生成"]},{"cell_type":"code","metadata":{},"source":["import datetime\n","\n","# 初回のみ\n","try:\n","    root = root\n","except NameError:\n","    try:\n","        # Google Driveのマウント\n","        from google.colab import drive\n","        drive.mount(\"/content/drive\")\n","        root = \"drive/My Drive/GAN\"\n","    except ModuleNotFoundError:\n","        # ローカルの場合\n","        root = \".\"\n","    finally:\n","        # ログ\n","        dt = datetime.datetime.today().strftime('%Y%m%d%H%M%S')\n","        gan.log_file_path = f\"{root}/log/{dt}.log\"\n","        \n","        # 学習ファイル読込み\n","        try:\n","            gan.loadWeights(f\"{root}/wgh\")\n","            print(\"前回のチェックポイントから再開\")\n","        except FileNotFoundError:\n","            print(\"最初から学習開始\")\n","\n","# 学習開始\n","for _ in range(10):\n","    gan.defit(x_train, epochs=10)\n","    gan.saveWeights(f\"{root}/wgt\")\n","    gan.generateImage(f\"{root}/img/{datetime.datetime.today().strftime('%Y%m%d%H%M%S')}_mnist_{gan.total_epochs}.png\", 20)\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["1 [==========================] D_MODEL - loss:0.2177, acc:89.89  G_MODEL - loss:0.1063\n","2 [==========================] D_MODEL - loss:0.6939, acc:64.98  G_MODEL - loss:0.5861\n","3 [==========================] D_MODEL - loss:0.7107, acc:46.50  G_MODEL - loss:0.7424\n","4 [==========================] D_MODEL - loss:0.6912, acc:52.30  G_MODEL - loss:0.7698\n","5 [==========================] D_MODEL - loss:0.6776, acc:58.90  G_MODEL - loss:0.8081\n","6 [==========================] D_MODEL - loss:0.6658, acc:62.98  G_MODEL - loss:0.8554\n","7 [==========================] D_MODEL - loss:0.6730, acc:59.91  G_MODEL - loss:0.8516\n","8 [==========================] D_MODEL - loss:0.6885, acc:54.36  G_MODEL - loss:0.7728\n","9 [==========================] D_MODEL - loss:0.6889, acc:54.72  G_MODEL - loss:0.7629\n","10 [==========================] D_MODEL - loss:0.6885, acc:54.78  G_MODEL - loss:0.7651\n","11 [==========================] D_MODEL - loss:0.6873, acc:55.40  G_MODEL - loss:0.7650\n","12 [==========================] D_MODEL - loss:0.6865, acc:55.56  G_MODEL - loss:0.7627\n","13 [==========================] D_MODEL - loss:0.6866, acc:55.18  G_MODEL - loss:0.7602\n","14 [==========================] D_MODEL - loss:0.6849, acc:56.10  G_MODEL - loss:0.7595\n","15 [==========================] D_MODEL - loss:0.6844, acc:55.99  G_MODEL - loss:0.7625\n","16 [==========================] D_MODEL - loss:0.6863, acc:55.57  G_MODEL - loss:0.7608\n","17 [==========================] D_MODEL - loss:0.6849, acc:55.49  G_MODEL - loss:0.7591\n","18 [==========================] D_MODEL - loss:0.6839, acc:56.40  G_MODEL - loss:0.7535\n","19 [==========================] D_MODEL - loss:0.6840, acc:55.96  G_MODEL - loss:0.7616\n","20 [==========================] D_MODEL - loss:0.6848, acc:55.96  G_MODEL - loss:0.7564\n","21 [==========================] D_MODEL - loss:0.6849, acc:55.79  G_MODEL - loss:0.7549\n","22 [==========================] D_MODEL - loss:0.6841, acc:55.88  G_MODEL - loss:0.7592\n","23 [==========================] D_MODEL - loss:0.6828, acc:55.90  G_MODEL - loss:0.7661\n","24 [==========================] D_MODEL - loss:0.6853, acc:55.51  G_MODEL - loss:0.7532\n","25 [==========================] D_MODEL - loss:0.6827, acc:56.26  G_MODEL - loss:0.7571\n","26 [==========================] D_MODEL - loss:0.6842, acc:55.73  G_MODEL - loss:0.7579\n","27 [==========================] D_MODEL - loss:0.6832, acc:55.98  G_MODEL - loss:0.7529\n","28 [==========================] D_MODEL - loss:0.6835, acc:55.84  G_MODEL - loss:0.7533\n","29 [==========================] D_MODEL - loss:0.6840, acc:56.39  G_MODEL - loss:0.7535\n","30 [==========================] D_MODEL - loss:0.6831, acc:56.01  G_MODEL - loss:0.7551\n","31 [==========================] D_MODEL - loss:0.6856, acc:55.30  G_MODEL - loss:0.7550\n","32 [==========================] D_MODEL - loss:0.6846, acc:55.34  G_MODEL - loss:0.7523\n","33 [==========================] D_MODEL - loss:0.6830, acc:56.65  G_MODEL - loss:0.7527\n","34 [==========================] D_MODEL - loss:0.6832, acc:55.89  G_MODEL - loss:0.7536\n","35 [==========================] D_MODEL - loss:0.6838, acc:55.97  G_MODEL - loss:0.7563\n","36 [==========================] D_MODEL - loss:0.6847, acc:55.73  G_MODEL - loss:0.7473\n","37 [==========================] D_MODEL - loss:0.6837, acc:55.68  G_MODEL - loss:0.7498\n","38 [==========================] D_MODEL - loss:0.6836, acc:55.72  G_MODEL - loss:0.7490\n","39 [==========================] D_MODEL - loss:0.6843, acc:55.83  G_MODEL - loss:0.7463\n","40 [==========================] D_MODEL - loss:0.6848, acc:55.71  G_MODEL - loss:0.7470\n","41 [==========================] D_MODEL - loss:0.6847, acc:55.23  G_MODEL - loss:0.7450\n","42 [==========================] D_MODEL - loss:0.6851, acc:55.22  G_MODEL - loss:0.7569\n","43 [==========================] D_MODEL - loss:0.6845, acc:55.19  G_MODEL - loss:0.7439\n","44 [==========================] D_MODEL - loss:0.6857, acc:55.33  G_MODEL - loss:0.7426\n","45 [==========================] D_MODEL - loss:0.6839, acc:55.68  G_MODEL - loss:0.7489\n","46 [==========================] D_MODEL - loss:0.6845, acc:56.01  G_MODEL - loss:0.7492\n","47 [==========================] D_MODEL - loss:0.6853, acc:55.21  G_MODEL - loss:0.7426\n","48 [==========================] D_MODEL - loss:0.6848, acc:55.37  G_MODEL - loss:0.7424\n","49 [==========================] D_MODEL - loss:0.6856, acc:55.30  G_MODEL - loss:0.7430\n","50 [==========================] D_MODEL - loss:0.6838, acc:56.48  G_MODEL - loss:0.7442\n","51 [==========================] D_MODEL - loss:0.6858, acc:55.32  G_MODEL - loss:0.7495\n","52 [==========================] D_MODEL - loss:0.6854, acc:55.30  G_MODEL - loss:0.7550\n","53 [==========================] D_MODEL - loss:0.6840, acc:55.91  G_MODEL - loss:0.7534\n","54 [==========================] D_MODEL - loss:0.6838, acc:55.65  G_MODEL - loss:0.7563\n","55 [==========================] D_MODEL - loss:0.6847, acc:55.44  G_MODEL - loss:0.7477\n","56 [==========================] D_MODEL - loss:0.6842, acc:55.79  G_MODEL - loss:0.7424\n","57 [==========================] D_MODEL - loss:0.6858, acc:54.80  G_MODEL - loss:0.7417\n","58 [==========================] D_MODEL - loss:0.6849, acc:55.61  G_MODEL - loss:0.7439\n","59 [==========================] D_MODEL - loss:0.6837, acc:56.10  G_MODEL - loss:0.7561\n","60 [==========================] D_MODEL - loss:0.6839, acc:55.92  G_MODEL - loss:0.7520\n","61 [==========================] D_MODEL - loss:0.6858, acc:55.20  G_MODEL - loss:0.7450\n","62 [==========================] D_MODEL - loss:0.6845, acc:55.24  G_MODEL - loss:0.7415\n","63 [==========================] D_MODEL - loss:0.6836, acc:55.87  G_MODEL - loss:0.7505\n","64 [==========================] D_MODEL - loss:0.6841, acc:55.77  G_MODEL - loss:0.7538\n","65 [==========================] D_MODEL - loss:0.6856, acc:55.13  G_MODEL - loss:0.7484\n","66 [==========================] D_MODEL - loss:0.6849, acc:55.05  G_MODEL - loss:0.7458\n","67 [==========================] D_MODEL - loss:0.6837, acc:55.82  G_MODEL - loss:0.7441\n","68 [==========================] D_MODEL - loss:0.6846, acc:55.68  G_MODEL - loss:0.7464\n","69 [==========================] D_MODEL - loss:0.6843, acc:55.56  G_MODEL - loss:0.7507\n","70 [==========================] D_MODEL - loss:0.6842, acc:55.43  G_MODEL - loss:0.7463\n","71 [==========================] D_MODEL - loss:0.6843, acc:54.88  G_MODEL - loss:0.7459\n","72 [==========================] D_MODEL - loss:0.6846, acc:55.61  G_MODEL - loss:0.7441\n","73 [==========================] D_MODEL - loss:0.6850, acc:55.28  G_MODEL - loss:0.7431\n","74 [==========================] D_MODEL - loss:0.6852, acc:55.05  G_MODEL - loss:0.7466\n","75 [==========================] D_MODEL - loss:0.6845, acc:55.09  G_MODEL - loss:0.7453\n","76 [==========================] D_MODEL - loss:0.6843, acc:55.48  G_MODEL - loss:0.7486\n","77 [==========================] D_MODEL - loss:0.6836, acc:55.52  G_MODEL - loss:0.7423\n","78 [==========================] D_MODEL - loss:0.6842, acc:55.05  G_MODEL - loss:0.7440\n","79 [==========================] D_MODEL - loss:0.6849, acc:55.07  G_MODEL - loss:0.7462\n","80 [==========================] D_MODEL - loss:0.6854, acc:55.37  G_MODEL - loss:0.7629\n","81 [==========================] D_MODEL - loss:0.6820, acc:56.25  G_MODEL - loss:0.7589\n","82 [==========================] D_MODEL - loss:0.6845, acc:55.00  G_MODEL - loss:0.7497\n","83 [==========================] D_MODEL - loss:0.6839, acc:55.98  G_MODEL - loss:0.7461\n","84 [==========================] D_MODEL - loss:0.6833, acc:55.62  G_MODEL - loss:0.7448\n","85 [==========================] D_MODEL - loss:0.6850, acc:55.40  G_MODEL - loss:0.7493\n","86 [==========================] D_MODEL - loss:0.6841, acc:55.09  G_MODEL - loss:0.7459\n","87 [==========================] D_MODEL - loss:0.6822, acc:55.58  G_MODEL - loss:0.7507\n","88 [==========================] D_MODEL - loss:0.6843, acc:55.30  G_MODEL - loss:0.7503\n","89 [==========================] D_MODEL - loss:0.6828, acc:55.80  G_MODEL - loss:0.7537\n","90 [==========================] D_MODEL - loss:0.6833, acc:55.77  G_MODEL - loss:0.7542\n","91 [==========================] D_MODEL - loss:0.6837, acc:55.13  G_MODEL - loss:0.7474\n","92 [==========================] D_MODEL - loss:0.6829, acc:56.05  G_MODEL - loss:0.7508\n","93 [==========================] D_MODEL - loss:0.6816, acc:56.34  G_MODEL - loss:0.7537\n","94 [==========================] D_MODEL - loss:0.6828, acc:55.91  G_MODEL - loss:0.7633\n","95 [==========================] D_MODEL - loss:0.6824, acc:56.04  G_MODEL - loss:0.7564\n","96 [==========================] D_MODEL - loss:0.6828, acc:55.98  G_MODEL - loss:0.7481\n","97 [==========================] D_MODEL - loss:0.6828, acc:56.03  G_MODEL - loss:0.7511\n","98 [==========================] D_MODEL - loss:0.6839, acc:55.19  G_MODEL - loss:0.7513\n","99 [==========================] D_MODEL - loss:0.6821, acc:56.19  G_MODEL - loss:0.7524\n","100 [==========================] D_MODEL - loss:0.6816, acc:55.91  G_MODEL - loss:0.7579\n"]}]},{"cell_type":"code","source":[""],"metadata":{},"execution_count":null,"outputs":[]}]}